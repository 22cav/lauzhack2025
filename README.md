# Multi-Input Gesture Control System

A modular, event-driven gesture control system that supports multiple input sources (webcam gestures, Bluetooth buttons) and multiple output targets (Blender, Logitech devices, system actions).

## ğŸ¯ Features

- **Multi-Input Support**:
  - ğŸ“¹ Webcam gesture recognition with MediaPipe
  - ğŸ® Enhanced gestures: pinch-drag for viewport control
  - ğŸ”˜ MX Creative Console Bluetooth button support
  - ğŸ“· MX Brio webcam optimization

- **Multi-Output Support**:
  - ğŸ¨ Blender integration for 3D viewport control
  - ğŸ›ï¸ Logitech/Loupedeck device integration (backward compatible)
  - ğŸ’» System-level actions (volume, media controls)

- **Event-Driven Architecture**:
  - ğŸ”„ Decoupled input producers and output consumers
  - âš™ï¸ Configurable event routing via YAML
  - ğŸ”§ Extensible plugin system

## ğŸš€ Quick Start

### ğŸ¨ **Live Demo with Blender** (Recommended)

See your gestures control Blender in real-time!

```bash
# Install dependencies
conda activate lauzhack
pip install -r requirements.txt

# Run the demo
python demo_blender.py
```

Follow the on-screen instructions to set up the Blender addon. See [DEMO_GUIDE.md](DEMO_GUIDE.md) for details.

### âš¡ **Quick Test** (No Blender needed)

```bash
# Test gesture recognition only
python main_orchestrator.py --config config/test_gesture_only.yaml
```

Perform gestures to control system volume and media playback.

## ğŸ“‹ What You Get

### Camera Visualization
- âœ… Live camera feed with skeleton tracking
- âœ… Hand landmarks overlay
- âœ… Current gesture displayed
- âœ… Visual feedback for all gestures

### Blender Control
- âœ… Pinch-drag to rotate viewport
- âœ… Gestures control timeline and playback
- âœ… Real-time response
- âœ… Visual command feedback in Blender

## ğŸ“š Documentation

- **[DEMO_GUIDE.md](DEMO_GUIDE.md)** - Complete Blender demo guide  
- **[QUICKSTART.md](QUICKSTART.md)** - 5-minute setup guide
- **[docs/SETUP.md](docs/SETUP.md)** - Detailed setup and configuration
- **[docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System design
- **[docs/README.md](docs/README.md)** - Documentation index

## ğŸ® Supported Gestures

### Basic Gestures
- ğŸ–ï¸ **Open Palm** - All fingers extended
- âœŠ **Closed Fist** - All fingers closed
- ğŸ‘† **Pointing** - Index finger extended

### Advanced Gestures
- ğŸ¤ **Pinch Start** - Thumb and index touch
- ğŸ–±ï¸ **Pinch Drag** - Move hand while pinching (for viewport control)
- ğŸ”“ **Pinch Release** - Fingers separate

## ğŸ“ Project Structure

```
lauzhack/
â”œâ”€â”€ demo_blender.py         # ğŸ¨ Blender demo launcher
â”œâ”€â”€ main_orchestrator.py    # Main entry point
â”‚
â”œâ”€â”€ blender_addon/          # Blender addon
â”‚   â””â”€â”€ gesture_control_addon.py
â”‚
â”œâ”€â”€ core/                   # Core event system
â”‚   â””â”€â”€ event_system.py
â”‚
â”œâ”€â”€ inputs/                 # Input modules
â”‚   â”œâ”€â”€ gesture_input.py    # Gesture recognition
â”‚   â””â”€â”€ mx_console_input.py # Bluetooth buttons
â”‚
â”œâ”€â”€ outputs/                # Output modules
â”‚   â”œâ”€â”€ blender_output.py   # Blender integration
â”‚   â”œâ”€â”€ loupedeck_output.py # Loupedeck plugin
â”‚   â””â”€â”€ system_output.py    # System actions
â”‚
â”œâ”€â”€ config/                 # YAML configurations
â”‚   â”œâ”€â”€ event_mappings.yaml
â”‚   â”œâ”€â”€ blender_mode.yaml
â”‚   â””â”€â”€ test_gesture_only.yaml
â”‚
â”œâ”€â”€ tests/                  # Unit tests
â””â”€â”€ docs/                   # Documentation
```

## âš™ï¸ Configuration

Edit `config/event_mappings.yaml` to customize:

```yaml
inputs:
  gesture:
    enabled: true
    camera_index: 0           # Change if you have multiple cameras
    pinch_threshold: 0.05     # Adjust sensitivity
  
  mx_console:
    enabled: false            # Set to true if you have MX Console

outputs:
  blender:
    enabled: true             # Blender integration
    mappings:
      PINCH_DRAG: viewport_rotate
      OPEN_PALM: play_animation
  
  system:
    enabled: true             # Volume/media controls
    mappings:
      OPEN_PALM: volumeup
      CLOSED_FIST: volumedown
```

## ğŸ§ª Testing

```bash
# Run unit tests
python -m pytest tests/ -v

# Test with Blender demo
python demo_blender.py

# Test gesture recognition only
python main_orchestrator.py --config config/test_gesture_only.yaml
```

## ğŸ”§ Development

### Adding New Gestures

Edit `inputs/gesture_input.py` â†’ `_detect_basic_gesture()`:

```python
if extended_fingers == 2:
    # Peace sign detection
    return "PEACE_SIGN"
```

Then map in config:
```yaml
mappings:
  PEACE_SIGN: nexttrack
```

### Adding New Outputs

1. Create `outputs/my_output.py`
2. Implement `start()` and `stop()` methods
3. Subscribe to events: `event_bus.subscribe(EventType.GESTURE, callback)`
4. Add to `main_orchestrator.py`
5. Configure in YAML

See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for details.

## ğŸ¬ Demo Videos

The `demo_blender.py` script provides a complete visual demonstration:
- Camera window shows live gesture detection
- Blender window responds in real-time
- Visual feedback for all commands

## ğŸ› Troubleshooting

### Camera Not Working
- Check `camera_index` in config (try 0, 1, 2...)
- Close other apps using camera
- Check permissions (System Preferences â†’ Camera)

### Blender Not Responding
- Verify addon is installed and enabled
- Check port 8888 is not blocked
- See [DEMO_GUIDE.md](DEMO_GUIDE.md#troubleshooting)

### Gestures Not Detected
- Improve lighting
- Keep hand 30-60cm from camera
- Lower `min_detection_confidence` in config

## ğŸ†˜ Getting Help

1. **Live Demo**: See [DEMO_GUIDE.md](DEMO_GUIDE.md)
2. **Setup**: See [docs/SETUP.md](docs/SETUP.md)
3. **Architecture**: See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)
4. **Tests**: Run `python -m pytest tests/ -v`

## ğŸ“ License

MIT

## ğŸ‘¥ Authors

Lauzhack Team

---

**ğŸ‰ Try the demo: `python demo_blender.py`**
